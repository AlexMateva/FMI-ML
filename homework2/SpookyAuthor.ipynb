{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 2) (8392, 1) (8392, 3)\n",
      "{'author'}\n"
     ]
    }
   ],
   "source": [
    "# Зареждане на данните\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"data/train.zip\", index_col=['id'])\n",
    "test = pd.read_csv(\"data/test.zip\", index_col=['id'])\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.zip\", index_col=['id'])\n",
    "\n",
    "print(train.shape, test.shape, sample_submission.shape)\n",
    "print(set(train.columns) - set(test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train.author = train.author.replace(['EAP', 'HPL', 'MWS'], ['Едгар', 'Хауърд', 'Мери'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGMJJREFUeJzt3Xu0nXV95/H3BwKCqBDgTIpJmDCa\nqUWriBnA0pmFouHSjsFWGJh2CJTVdNaiXqYzneKsNZMWpAuXdhjRgVlZEgnWASlIyTiMNI0yU+1w\nCRe5ijmikGRxSUlEEcGG+c4f+3dkG85JzhPPPjuX92utvfbv+T6/59m/nX1yPue57lQVkiRN1l7D\nHoAkaddicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHUyY9gDGIRDDz205s2b\nN+xhSNIu5a677vq7qhrZXr/dMjjmzZvHmjVrhj0MSdqlJHlsMv3cVSVJ6sTgkCR1MtDgSPJvkjyY\n5IEk1yTZL8kRSW5PMprki0n2bX1f1aZH2/x5fev5aKs/kuSkQY5ZkrRtAwuOJLOBDwELquotwN7A\nmcDHgUur6o3AZuC8tsh5wOZWv7T1I8mRbbk3AycDlyfZe1DjliRt26B3Vc0A9k8yA3g18ATwbuD6\nNn8FcFprL2rTtPknJkmrX1tVL1bVd4FR4JgBj1uSNIGBBUdVbQA+CTxOLzCeBe4Cvl9VW1q39cDs\n1p4NrGvLbmn9D+mvj7OMJGmaDXJX1Ux6WwtHAK8HDqC3q2lQr7ckyZokazZu3Diol5GkPd4gd1W9\nB/huVW2sqr8HvgQcDxzUdl0BzAE2tPYGYC5Am38g8Ex/fZxlfqqqllXVgqpaMDKy3etXJEk7aJDB\n8ThwXJJXt2MVJwIPAV8DPtD6LAZuau2VbZo2/6vV+0L0lcCZ7ayrI4D5wB0DHLckaRsGduV4Vd2e\n5HrgbmALcA+wDPifwLVJPtZqV7ZFrgQ+n2QU2ETvTCqq6sEk19ELnS3A+VX10lSN8x1/ePVUrUrb\ncNcnzh72ECRNkYHecqSqlgJLtyo/yjhnRVXVC8DpE6znYuDiKR+gJKkzrxyXJHVicEiSOjE4JEmd\nGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS\n1InBIUnqxOCQJHVicEiSOhlYcCT5xST39j1+kOQjSQ5OsirJ2vY8s/VPksuSjCa5L8nRfeta3Pqv\nTbJ4UGOWJG3fwIKjqh6pqqOq6ijgHcDzwI3ABcDqqpoPrG7TAKcA89tjCXAFQJKD6X1v+bH0vqt8\n6VjYSJKm33TtqjoR+E5VPQYsAla0+grgtNZeBFxdPbcBByU5DDgJWFVVm6pqM7AKOHmaxi1J2sp0\nBceZwDWtPauqnmjtJ4FZrT0bWNe3zPpWm6j+M5IsSbImyZqNGzdO5dglSX0GHhxJ9gXeB/zF1vOq\nqoCaitepqmVVtaCqFoyMjEzFKiVJ45iOLY5TgLur6qk2/VTbBUV7frrVNwBz+5ab02oT1SVJQzAd\nwXEWL++mAlgJjJ0ZtRi4qa9+dju76jjg2bZL6xZgYZKZ7aD4wlaTJA3BjEGuPMkBwHuB3+srXwJc\nl+Q84DHgjFa/GTgVGKV3Bta5AFW1KclFwJ2t34VVtWmQ45YkTWygwVFVPwIO2ar2DL2zrLbuW8D5\nE6xnObB8EGOUJHXjleOSpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4M\nDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4GGhxJDkpyfZJvJXk4yTuTHJxk\nVZK17Xlm65sklyUZTXJfkqP71rO49V+bZPHEryhJGrRBb3F8CvhKVb0JeBvwMHABsLqq5gOr2zTA\nKcD89lgCXAGQ5GBgKXAscAywdCxsJEnTb2DfOZ7kQOCfAecAVNVPgJ8kWQSc0LqtAG4F/ghYBFzd\nvnv8tra1cljru6qqNrX1rgJOBq4Z1NglTY/jP338sIew2/vGB78x5esc5BbHEcBG4HNJ7kny2SQH\nALOq6onW50lgVmvPBtb1Lb++1SaqS5KGYJDBMQM4Griiqt4O/IiXd0sB0LYuaipeLMmSJGuSrNm4\nceNUrFKSNI5BBsd6YH1V3d6mr6cXJE+1XVC056fb/A3A3L7l57TaRPWfUVXLqmpBVS0YGRmZ0jci\nSXrZwIKjqp4E1iX5xVY6EXgIWAmMnRm1GLiptVcCZ7ezq44Dnm27tG4BFiaZ2Q6KL2w1SdIQDOzg\nePNB4AtJ9gUeBc6lF1bXJTkPeAw4o/W9GTgVGAWeb32pqk1JLgLubP0uHDtQLkmafgMNjqq6F1gw\nzqwTx+lbwPkTrGc5sHxqRydJ2hFeOS5J6sTgkCR1YnBIkjoxOCRJnQz6rCppoB6/8JeHPYTd3uH/\n6f5hD0E7Gbc4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4M\nDklSJwaHJKmTgQZHku8luT/JvUnWtNrBSVYlWdueZ7Z6klyWZDTJfUmO7lvP4tZ/bZLFE72eJGnw\npmOL411VdVRVjX2F7AXA6qqaD6xu0wCnAPPbYwlwBfSCBlgKHAscAywdCxtJ0vQbxq6qRcCK1l4B\nnNZXv7p6bgMOSnIYcBKwqqo2VdVmYBVw8nQPWpLUM+jgKOCvktyVZEmrzaqqJ1r7SWBWa88G1vUt\nu77VJqpLkoZg0F/k9KtVtSHJPwBWJflW/8yqqiQ1FS/UgmkJwOGHHz4Vq5QkjWOgWxxVtaE9Pw3c\nSO8YxVNtFxTt+enWfQMwt2/xOa02UX3r11pWVQuqasHIyMhUvxVJUjOw4EhyQJLXjrWBhcADwEpg\n7MyoxcBNrb0SOLudXXUc8GzbpXULsDDJzHZQfGGrSZKGYJC7qmYBNyYZe53/XlVfSXIncF2S84DH\ngDNa/5uBU4FR4HngXICq2pTkIuDO1u/Cqto0wHFLkrZhYMFRVY8Cbxun/gxw4jj1As6fYF3LgeVT\nPUZJUndeOS5J6sTgkCR1YnBIkjoxOCRJnRgckqROJhUcSVZPpiZJ2v1t83TcJPsBrwYObRffpc16\nHd4vSpL2SNu7juP3gI8Arwfu4uXg+AHwmQGOS5K0k9pmcFTVp4BPJflgVX16msYkSdqJTerK8ar6\ndJJfAeb1L1NVVw9oXJKkndSkgiPJ54E3APcCL7VyAQaHJO1hJnuvqgXAke1+UpKkPdhkr+N4APiF\nQQ5EkrRrmOwWx6HAQ0nuAF4cK1bV+wYyKknSTmuywfHHgxyEJGnXMdmzqv73oAciSdo1TPasqh/S\nO4sKYF9gH+BHVfW6QQ1MkrRzmtTB8ap6bVW9rgXF/sBvApdPZtkkeye5J8mX2/QRSW5PMprki0n2\nbfVXtenRNn9e3zo+2uqPJDmp43uUJE2hznfHrZ6/BCb7C/zDwMN90x8HLq2qNwKbgfNa/Txgc6tf\n2vqR5EjgTODNwMnA5Un27jpuSdLUmOzdcX+j7/GBJJcAL0xiuTnArwGfbdMB3g1c37qsAE5r7UVt\nmjb/xNZ/EXBtVb1YVd8FRoFjJvXuJElTbrJnVf3zvvYW4Hv0fqFvz38B/j3w2jZ9CPD9qtrSptfz\n8l12ZwPrAKpqS5JnW//ZwG196+xfRpI0zSZ7VtW5XVec5NeBp6vqriQndF1+B15vCbAE4PDDDx/0\ny0nSHmuyu6rmJLkxydPtcUPbDbUtxwPvS/I94Fp6u6g+BRyUZCyw5gAbWnsDMLe93gzgQOCZ/vo4\ny/xUVS2rqgVVtWBkZGQyb0uStAMme3D8c8BKet/L8Xrgf7TahKrqo1U1p6rm0Tu4/dWq+i3ga8AH\nWrfFwE2tvbJN0+Z/td0bayVwZjvr6ghgPnDHJMctSZpikw2Okar6XFVtaY+rgB39s/6PgD9IMkrv\nGMaVrX4lcEir/wFwAUBVPQhcBzwEfAU4v6peesVaJUnTYrIHx59J8tvANW36LHq7kSalqm4Fbm3t\nRxnnrKiqegE4fYLlLwYunuzrSZIGZ7JbHL8DnAE8CTxBb1fSOQMakyRpJzbZLY4LgcVVtRkgycHA\nJ+kFiiRpDzLZLY63joUGQFVtAt4+mCFJknZmkw2OvZLMHJtoWxyT3VqRJO1GJvvL/8+A/5vkL9r0\n6XiwWpL2SJO9cvzqJGvoXcQH8BtV9dDghiVJ2llNendTCwrDQpL2cJ1vqy5J2rMZHJKkTgwOSVIn\nBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgYWHEn2S3JHkm8meTDJn7T6EUluTzKa\n5ItJ9m31V7Xp0TZ/Xt+6PtrqjyQ5aVBjliRt3yC3OF4E3l1VbwOOAk5OchzwceDSqnojsBk4r/U/\nD9jc6pe2fiQ5EjgTeDNwMnB5kr0HOG5J0jYMLDiq57k2uU97FL077F7f6iuA01p7UZumzT8xSVr9\n2qp6saq+C4wyzneWS5Kmx0CPcSTZO8m9wNPAKuA7wPerakvrsh6Y3dqzgXUAbf6zwCH99XGWkSRN\ns4EGR1W9VFVHAXPobSW8aVCvlWRJkjVJ1mzcuHFQLyNJe7xpOauqqr4PfA14J3BQkrHvAZkDbGjt\nDcBcgDb/QOCZ/vo4y/S/xrKqWlBVC0ZGRgbyPiRJgz2raiTJQa29P/Be4GF6AfKB1m0xcFNrr2zT\ntPlfrapq9TPbWVdHAPOBOwY1bknStk36GwB3wGHAinYG1F7AdVX15SQPAdcm+RhwD3Bl638l8Pkk\no8AmemdSUVUPJrmO3rcPbgHOr6qXBjhuSdI2DCw4quo+4O3j1B9lnLOiquoF4PQJ1nUxcPFUj1GS\n1J1XjkuSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4M\nDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdDCw4ksxN8rUkDyV5MMmHW/3gJKuSrG3P\nM1s9SS5LMprkviRH961rceu/NsniQY1ZkrR9g9zi2AL826o6EjgOOD/JkcAFwOqqmg+sbtMApwDz\n22MJcAX0ggZYChxL77vKl46FjSRp+g0sOKrqiaq6u7V/CDwMzAYWAStatxXAaa29CLi6em4DDkpy\nGHASsKqqNlXVZmAVcPKgxi1J2rZpOcaRZB7wduB2YFZVPdFmPQnMau3ZwLq+xda32kT1rV9jSZI1\nSdZs3LhxSscvSXrZwIMjyWuAG4CPVNUP+udVVQE1Fa9TVcuqakFVLRgZGZmKVUqSxjHQ4EiyD73Q\n+EJVfamVn2q7oGjPT7f6BmBu3+JzWm2iuiRpCAZ5VlWAK4GHq+o/981aCYydGbUYuKmvfnY7u+o4\n4Nm2S+sWYGGSme2g+MJWkyQNwYwBrvt44F8B9ye5t9X+A3AJcF2S84DHgDPavJuBU4FR4HngXICq\n2pTkIuDO1u/Cqto0wHFLkrZhYMFRVV8HMsHsE8fpX8D5E6xrObB86kYnSdpRXjkuSerE4JAkdWJw\nSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVIn\nBockqRODQ5LUicEhSepkkN85vjzJ00ke6KsdnGRVkrXteWarJ8llSUaT3Jfk6L5lFrf+a5MsHu+1\nJEnTZ5BbHFcBJ29VuwBYXVXzgdVtGuAUYH57LAGugF7QAEuBY4FjgKVjYSNJGo6BBUdV/R9g01bl\nRcCK1l4BnNZXv7p6bgMOSnIYcBKwqqo2VdVmYBWvDCNJ0jSa7mMcs6rqidZ+EpjV2rOBdX391rfa\nRHVJ0pAM7eB4VRVQU7W+JEuSrEmyZuPGjVO1WknSVqY7OJ5qu6Boz0+3+gZgbl+/Oa02Uf0VqmpZ\nVS2oqgUjIyNTPnBJUs90B8dKYOzMqMXATX31s9vZVccBz7ZdWrcAC5PMbAfFF7aaJGlIZgxqxUmu\nAU4ADk2ynt7ZUZcA1yU5D3gMOKN1vxk4FRgFngfOBaiqTUkuAu5s/S6sqq0PuEuSptHAgqOqzppg\n1onj9C3g/AnWsxxYPoVDkyT9HLxyXJLUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBock\nqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUyS4THElOTvJIktEk\nFwx7PJK0p9olgiPJ3sB/BU4BjgTOSnLkcEclSXumXSI4gGOA0ap6tKp+AlwLLBrymCRpj7SrBMds\nYF3f9PpWkyRNsxnDHsBUSbIEWNImn0vyyDDHM2CHAn837EF0kU8uHvYQdia71ue3NMMewc5k1/rs\ngHyo0+f3DyfTaVcJjg3A3L7pOa32U1W1DFg2nYMaliRrqmrBsMehHePnt+vys+vZVXZV3QnMT3JE\nkn2BM4GVQx6TJO2RdoktjqrakuT3gVuAvYHlVfXgkIclSXukXSI4AKrqZuDmYY9jJ7FH7JLbjfn5\n7br87IBU1bDHIEnahewqxzgkSTsJg2OIkryU5N6+h7dS2QklmZvku0kObtMz2/S84Y5MP68kleTP\n+6ZnJNmY5MvDHNfObpc5xrGb+nFVHTXsQWjbqmpdkiuAS+hdK3QJsKyqvjfUgWkq/Ah4S5L9q+rH\nwHvZ6lR/vZJbHDupJA8keahtiTzXV+/fSvnrVvvdJHcm+WaSG5K8utWvSvLfkqxJ8u0kvz6s97Mb\nuBQ4LslHgF8FPpnkNUlWJ7k7yf1JFgEkubD1o01fnOTDST639efZ12dekm8l+UKSh5NcP/Y5tvnj\n/jxoStwM/FprnwVcMzYjyQFJlie5I8k9fZ/xOUluSnJrkrVJlrb6vCQPtPY+SR5N8plpfj+DV1U+\nhvQAXgLu7Xv8i755DwOHt/ZzffXnxlnPIX3tjwEfbO2rgK/Q+wNhPr1btew37Pe9qz6Ak4AC3tum\nZwCva+1DgVEgwDzg7lbfC/jOVp/ReJ/hvLbu49v0cuDfbe/nwcfP/Zk+B7wVuB7Yr/0/PAH4cpv/\np8Bvt/ZBwLeBA4BzgCeAQ4D9gQeABe1zfKD1Px+4D/jMsN/nVD/c4hiuH1fVUX2PL/bNew2waZLr\neUuSv0lyP/BbwJv75l1XVf+vqtYCjwJvmpqh75FOoffL4i1tOsCfJrkP+Gt690+bVb1dWM8keTuw\nELinqp7pW8/+bcvhm0kuSzL2/3BdVX2jtf+c3pbNmC4/D+qgqu6j9wv/LF55yv9C4IIk9wK30guX\nw9u8VVX1TPV2cX2Jvs8ryQHAucDlAx38kHiMYyeUZD96WwaT3SVxFXBaVX0zyTn0/mIas/X51p5/\nvQOSHEVv//dxwNeTXEtvC2QEeEdV/X2S79H7xQLwWXp/lf4Cva2Hfj+uqqOSzABWAe+h95fsuJ/V\nDvw8qLuVwCfp/d85pK8e4Der6mfufZfkWLb9f+vD9K75+MmUj3Qn4BbHzun99K6Sn6zXAk8k2Yfe\nFke/05PsleQNwD8CduebPw5EkgBXAB+pqseBT9D7JXMg8HQLjXfxszeIuxE4GfgnTPBZVtUW4Hlg\n31Y6PMk7W/tfAl9v7a4/D+puOfAnVXX/VvVbgA+2nwHaVuSY9yY5OMn+wGnA2NbigW166z8YdhsG\nx3CN7bIYe1ySZAFwJXDCWL31u3Ab6/mPwO30fnC/tdW8x4E7gP8F/OuqemEA72N397vA41W1qk1f\nDvwSvf3hC9ouwrPp+7ev3vfGfI3ersKXtlrf2Of+AL197GOh8AhwfpKHgZnAFTv486COqmp9VV02\nzqyLgH2A+5I82KbH3AHcQO84xg1VtabV5wB/1v4w2C155fhOJskJwAlV9cd9tdfQO8B2Tsd1XUXv\nIN/1UzhETUI7bnE3cHo7vrS9/vPofVZv2ap+AlP086Cp03YJL6iq3x/2WIbBYxw7n4d45f3+X6C3\nq0S7gPS+1vjLwI2TCY3t8OdBOx23OCRJnXiMQ5LUicEhSerE4JAkdWJwSAOW5LR2wHxs+tZ2mq20\nSzI4pME7DThyu70moV1tLg2VwSHtgCR/meSuJA8mWdJq/Xcx/kC7O/GvAO8DPtEu4HtD63J6u+Pq\nt5P807bMfu0Ouve3O7G+q9XPSbIyyVeB1dP7TqVX8q8Xacf8TlVtarebuDPJDeN1qqq/TbKSvgsx\n290rZlTVMUlOBZbSu1/V+b1F6peTvAn4qyT/uK3qaOCtVeWNDjV0Boe0Yz6U5P2tPZfebeu7+FJ7\nvovenVmhd3fVTwNU1beSPAaMBccqQ0M7C4ND6qjdBuQ9wDur6vkkt9K7K27/1bT7jbNovxfb80tM\n7v/hjzoOUxoYj3FI3R0IbG6h8SZ6t1oHeCrJL7X7VL2/r/8P6d3BeHv+hnZ347aL6nC8m7F2QgaH\n1N1XgBntLraXALe1+gX07lH1t/S+8GnMtcAftgPeb2BilwN7tbvtfhE4p6pe3EZ/aSi8V5UkqRO3\nOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjr5/2ng+xofaDmIAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f477753a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "sns.countplot(data=train, x='author');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most used words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "the     33296\n",
       "of      20851\n",
       "and     17059\n",
       "to      12615\n",
       "I       10382\n",
       "a       10359\n",
       "in       8787\n",
       "was      6440\n",
       "that     5988\n",
       "my       5037\n",
       "had      4324\n",
       "with     4207\n",
       "his      3802\n",
       "as       3528\n",
       "he       3422\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = train['text'].str.split(expand=True).unstack().value_counts()\n",
    "print(\"Most used words\")\n",
    "all_words.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap = train[train.author==\"Едгар\"].text.values\n",
    "hpl = train[train.author==\"Хауърд\"].text.values\n",
    "mws = train[train.author==\"Мери\"].text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78783701,  0.79635305,  0.79509579])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', CountVectorizer()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48631897, -0.4762863 , -0.479489  ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "pipeline = Pipeline([\n",
    "    ('features', CountVectorizer()),\n",
    "    ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))\n",
    "])\n",
    "\n",
    "cross_val_score(pipeline, train.text, train.author, scoring='neg_log_loss', cv=3, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.62277497, -0.62149725, -0.61790357])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))\n",
    "])\n",
    "\n",
    "cross_val_score(pipeline, train.text, train.author, scoring='neg_log_loss', cv=3, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords)\n",
    "\n",
    "params_count_word = {\"features__ngram_range\": [(1,2), (1,3), (2, 3)],\n",
    "                      \"features__analyzer\": ['word'],\n",
    "                      \"features__max_df\":[1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1 , 0.05],\n",
    "                      \"features__min_df\":[2, 3, 5, 7, 10],\n",
    "                      \"features__lowercase\": [False, True],\n",
    "                      \"features__stop_words\": [None, stopwords]}\n",
    "\n",
    "params_count_char = {\"features__ngram_range\": [(1,4), (1,5), (1,6), (2, 5), (2, 6), (3, 5), (3, 6)],\n",
    "                      \"features__analyzer\": ['char'],\n",
    "                      \"features__max_df\":[1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1 , 0.05],\n",
    "                      \"features__min_df\":[2, 3, 5, 7, 10],\n",
    "                      \"features__lowercase\": [False, True],\n",
    "                      \"features__stop_words\": [None, stopwords]}\n",
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "def random_search():\n",
    "    params = {\n",
    "        \"clf__alpha\": [0.01, 0.1, 0.5, 1, 2]\n",
    "    }\n",
    "\n",
    "    params.update(params_count_word)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('features', CountVectorizer()),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=params, \n",
    "                                       scoring='neg_log_loss',\n",
    "                                       n_iter=20, cv=3, n_jobs=4)\n",
    "\n",
    "    random_search.fit(train.text, train.author)\n",
    "    report(random_search.cv_results_)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.500 (std: 0.009)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__max_df': 0.6, 'clf__alpha': 0.5, 'features__min_df': 3, 'features__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'], 'features__lowercase': False, 'features__analyzer': 'word'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.503 (std: 0.010)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__max_df': 0.7, 'clf__alpha': 0.5, 'features__min_df': 2, 'features__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'], 'features__lowercase': True, 'features__analyzer': 'word'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.520 (std: 0.008)\n",
      "Parameters: {'features__ngram_range': (1, 2), 'features__max_df': 0.5, 'clf__alpha': 0.5, 'features__min_df': 5, 'features__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'], 'features__lowercase': False, 'features__analyzer': 'word'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.590 (std: 0.013)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__max_df': 0.6, 'clf__alpha': 0.1, 'features__min_df': 5, 'features__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'], 'features__lowercase': False, 'features__analyzer': 'word'}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.637 (std: 0.015)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__max_df': 0.7, 'clf__alpha': 2, 'features__min_df': 3, 'features__stop_words': None, 'features__lowercase': False, 'features__analyzer': 'word'}\n",
      "\n",
      "[-0.48631897 -0.4762863  -0.479489  ]\n"
     ]
    }
   ],
   "source": [
    "random_search()\n",
    "pipeline = Pipeline([\n",
    "    ('features', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[ 0.83976716  0.84753295  0.84781609]\n",
      "[-1.2407899  -1.21859699 -1.23812869]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', CountVectorizer(ngram_range=(1, 2),\n",
    "                                 min_df=2,\n",
    "                                 max_df=0.8,\n",
    "                                 lowercase=False,\n",
    "                                 tokenizer=stemming_tokenizer)),\n",
    "#                                  stop_words=stopwords.words('english') + list(string.punctuation))),\n",
    "    ('clf', MultinomialNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=5))\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=5, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[ 0.84129902  0.84829911  0.8456705 ]\n",
      "[-0.39106583 -0.38602577 -0.38741785]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(ngram_range=(1, 2),\n",
    "                                 min_df=2,\n",
    "                                 max_df=0.8,\n",
    "                                 lowercase=False,\n",
    "                                 tokenizer=stemming_tokenizer)),\n",
    "#                                  stop_words=stopwords.words('english') + list(string.punctuation))),\n",
    "    ('clf', MultinomialNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=5))\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=5, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[ 0.84436275  0.84875881  0.84689655]\n",
      "[-0.38803888 -0.38472538 -0.38957178]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, ISRIStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "def stemming_tokenizer(text):\n",
    "    stemmer = ISRIStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(ngram_range=(1, 2),\n",
    "                                 min_df=2,\n",
    "                                 max_df=0.8,\n",
    "                                 lowercase=False,\n",
    "                                 tokenizer=stemming_tokenizer)),\n",
    "#                                  stop_words=stopwords.words('english') + list(string.punctuation))),\n",
    "    ('clf', MultinomialNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=8))\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=8, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66283701  0.64817652  0.66099617]\n",
      "[-0.89955223 -0.90454158 -0.89679078]\n"
     ]
    }
   ],
   "source": [
    "def stemming_tokenizer(text):\n",
    "    stemmer = ISRIStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(ngram_range=(1, 2),\n",
    "                                 min_df=2,\n",
    "                                 max_df=0.8,\n",
    "                                 lowercase=False,\n",
    "                                 tokenizer=stemming_tokenizer)),\n",
    "    ('clf', RandomForestClassifier(n_estimators=40, n_jobs=8, random_state=120, max_depth=40, criterion='gini'))\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=8))\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=8, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l1 ................\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l1 ................\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l1, score=-0.9174739548471665, total=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   1 | elapsed:   13.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l1, score=-0.9274827984653506, total=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   1 | elapsed:   13.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l1, score=-0.9082483231620134, total=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   1 | elapsed:   13.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l1, score=-0.9181243829255114, total=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   2 | elapsed:   26.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l1, score=-0.9181371455212605, total=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   2 | elapsed:   26.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l1, score=-0.9214623680409578, total=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   2 | elapsed:   26.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l1, score=-0.9282811303463558, total=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:   39.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l1, score=-0.9201532738484897, total=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:   39.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l1, score=-0.9185220879585279, total=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:   39.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l1, score=-0.9175860770777683, total=  17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   4 out of   4 | elapsed:   56.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l1, score=-0.9271388049802423, total=  17.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   4 out of   4 | elapsed:   56.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l1, score=-0.9079113625376712, total=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   4 out of   4 | elapsed:   58.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l1, score=-0.9176840567918837, total=  16.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   5 out of   5 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l1, score=-0.9189575339529413, total=  17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   5 out of   5 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l1, score=-0.9214633193305052, total=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   5 out of   5 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l1, score=-0.9311353508638641, total=  16.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of   6 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l1, score=-0.920007672465314, total=  16.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of   6 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l1, score=-0.9178654633035175, total=  18.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of   6 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l2, score=-0.9758332225305264, total=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   7 out of   7 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l2, score=-0.9726276343977142, total=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   7 out of   7 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l2, score=-0.9702510838634367, total=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   7 out of   7 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l2, score=-0.9695390424598719, total=  11.1s\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l2, score=-0.9738933333969855, total=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  1.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l2, score=-0.969903617889489, total=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l2, score=-0.9699208092324847, total=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   9 out of   9 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l2, score=-0.9747477176392872, total=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   9 out of   9 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=120, lr__penalty=l2, score=-0.9689996424544572, total=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   9 out of   9 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l2, score=-0.9688760420973849, total=  15.6s\n",
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l2, score=-0.967040323960806, total=  16.6s\n",
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l2, score=-0.9642452613363007, total=  18.6s\n",
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l2, score=-0.9635522493922293, total=  18.7s\n",
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l2, score=-0.9685069125819684, total=  17.3s\n",
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l2, score=-0.9658358952441434, total=  18.8s\n",
      "[CV] lr__C=0.1, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l2, score=-0.9697295534864865, total=  16.8s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l2, score=-0.9641122788385218, total=  17.3s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=0.1, svd__n_components=180, lr__penalty=l2, score=-0.9640442433455467, total=  18.4s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l1, score=-0.745610624348042, total=  11.5s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l1, score=-0.7488581417456167, total=  11.4s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l1, score=-0.7307418190939358, total=  11.8s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l1, score=-0.7494573643208358, total=  11.0s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l1, score=-0.7347390000848536, total=  11.5s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l1, score=-0.7371460144240554, total=  11.5s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l1, score=-0.7454468829486407, total=  11.3s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l1, score=-0.7245976598075735, total=  11.4s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l1, score=-0.7436428851921685, total=  11.7s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l1, score=-0.6954199197185338, total=  18.6s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l1, score=-0.7011532378094066, total=  17.9s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l1, score=-0.690576856665826, total=  19.7s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l1, score=-0.7011747578838045, total=  19.1s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l1, score=-0.687481232368416, total=  19.2s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l1, score=-0.7012997190842147, total=  18.1s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l1 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l1, score=-0.6933465210331945, total=  18.4s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l1, score=-0.7062922280730574, total=  18.9s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l2, score=-0.8098835911206352, total=  11.0s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l2, score=-0.800265883712841, total=  11.1s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l1, score=-0.6949060643162237, total=  18.9s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l2, score=-0.7924134845584468, total=  11.1s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l2, score=-0.8041080176488368, total=  11.4s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l2, score=-0.7966831058715057, total=  12.6s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l2, score=-0.792679600411762, total=  11.6s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l2, score=-0.8073123718303695, total=  11.7s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l2, score=-0.7965741269916473, total=  13.4s\n",
      "[CV] lr__C=1.0, svd__n_components=120, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=120, lr__penalty=l2, score=-0.7938137375300117, total=  12.6s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l2, score=-0.7774331206343821, total=  17.7s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l2, score=-0.7723368837631814, total=  17.3s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l2, score=-0.7658201723387598, total=  17.8s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l2, score=-0.7661666393867497, total=  17.5s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l2, score=-0.7768522809903097, total=  17.6s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l2, score=-0.7712187417600567, total=  17.3s\n",
      "[CV] lr__C=1.0, svd__n_components=180, lr__penalty=l2 ................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l2, score=-0.7596008956587916, total=  17.1s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l1 .................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l2, score=-0.7828529980132729, total=  17.3s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l1, score=-0.7225348964765731, total=  13.9s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l1, score=-0.7203300385101069, total=  13.1s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l1 .................\n",
      "[CV]  lr__C=1.0, svd__n_components=180, lr__penalty=l2, score=-0.7642867853033204, total=  14.9s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l1, score=-0.7166106795743105, total=  12.7s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l1, score=-0.7186968089924706, total=  12.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l1, score=-0.7187000003667421, total=  13.1s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l1, score=-0.7089932289205477, total=  11.8s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l1, score=-0.7389254313586469, total=  11.9s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l1, score=-0.7209625670660275, total=  12.8s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l1, score=-0.7208366299176455, total=  14.7s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l1, score=-0.6624891748006169, total=  17.4s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l1, score=-0.6763488697618306, total=  17.8s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l1, score=-0.661395741915166, total=  19.2s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l1, score=-0.6856564124123887, total=  19.0s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l1, score=-0.6681986131127333, total=  19.1s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l1, score=-0.6684849901330532, total=  19.4s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l1 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l1, score=-0.6797281271617496, total=  19.2s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l1, score=-0.6496527027273457, total=  19.2s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l2, score=-0.7325090352258544, total=  11.7s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l2, score=-0.7295460692775202, total=  11.8s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l1, score=-0.6587778354582585, total=  18.6s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l2, score=-0.7193363318100916, total=  10.8s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l2, score=-0.7308122957105503, total=  11.2s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l2, score=-0.7158180834292835, total=  12.3s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l2, score=-0.7107344452656155, total=  11.2s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l2, score=-0.7407102184780425, total=  11.2s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l2, score=-0.7363122392616113, total=  11.3s\n",
      "[CV] lr__C=10, svd__n_components=120, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l2, score=-0.683507796185179, total=  17.2s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l2, score=-0.6756922570595363, total=  17.8s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=120, lr__penalty=l2, score=-0.7171791906471515, total=  12.1s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l2, score=-0.6766632936575695, total=  18.7s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l2, score=-0.6824524751622146, total=  18.7s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l2, score=-0.6683126576910512, total=  17.9s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l2, score=-0.6918610499336034, total=  17.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  36 out of  36 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l2, score=-0.6623347979393926, total=  18.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  36 out of  36 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l2, score=-0.6894158005514163, total=  17.7s\n",
      "[CV] lr__C=10, svd__n_components=180, lr__penalty=l2 .................\n",
      "[CV]  lr__C=10, svd__n_components=180, lr__penalty=l2, score=-0.6630880573688971, total=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  36 out of  36 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6551318  -0.66593556 -0.65790207]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize SVD\n",
    "svd = TruncatedSVD()\n",
    "    \n",
    "\n",
    "\n",
    "# We will use logistic regression here..\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "                         ('lr', lr_model)])\n",
    "\n",
    "param_grid = {'svd__n_components' : [120, 180],\n",
    "              'lr__C': [0.1, 1.0, 10], \n",
    "              'lr__penalty': ['l1', 'l2']}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(ngram_range=(1, 2),\n",
    "                                 min_df=2,\n",
    "                                 max_df=0.8,\n",
    "                                 lowercase=False,\n",
    "                                 tokenizer=stemming_tokenizer)),\n",
    "    ('clf', GridSearchCV(estimator=clf, param_grid=param_grid, scoring='neg_log_loss',\n",
    "                                 verbose=10, n_jobs=8, iid=True, refit=True, cv=3))\n",
    "])\n",
    "\n",
    "#print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=8))\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=8, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
